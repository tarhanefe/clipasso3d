{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e2168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from source.beziercurve import BezierCurve\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "from source.utils import load_scene\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from source.sampler import ImageSampler\n",
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa09f264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alberts/Documents/EPFL/MA2/Visual_Intelligence/clipasso3d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberts/miniconda3/envs/3dsketch/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4d1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoload file changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56376dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means.shape torch.Size([16, 327, 3])\n",
      "thicknesses.shape torch.Size([16, 327])\n"
     ]
    }
   ],
   "source": [
    "# 1) load scene\n",
    "image = 9\n",
    "device = 'cuda'\n",
    "W, H = 224, 224\n",
    "\n",
    "# --- Prepare data sampler for a single scene ---\n",
    "data_name = 'chair'\n",
    "transforms_json = \"data/{}/transforms_train.json\".format(data_name)\n",
    "image_dir = 'data/{}'.format(data_name)\n",
    "sampler = ImageSampler(\n",
    "    transforms_json=transforms_json,\n",
    "    image_dir=image_dir,\n",
    "    width=W,\n",
    "    height=H,\n",
    "    total_iters=0,  # unused in random sampling\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "w2c = sampler.w2c_all[:batch_size]\n",
    "K = sampler.K\n",
    "\n",
    "#file_paths, c2w_mats, K = load_scene(\"data/transforms_train.json\", W, H, device=device)\n",
    "#w2c = torch.linalg.inv(c2w_mats[9]) \n",
    "#w2c = repeat(w2c, \"c1 c2 -> b c1 c2\", b=batch_size)  # (B,4,4)\n",
    "\n",
    "# 3) instantiate Bezier curve around scene center\n",
    "#    here control points in [-1,1]^3 space around the origin\n",
    "init_pts1 = torch.tensor([\n",
    "    [-1.0, 0.0, 0.0],\n",
    "    [-0.5, 0.5, 0.2],\n",
    "    [ 0.5,-0.5, 0.3],\n",
    "    [ 1.0, 0.0, 0.0]\n",
    "], dtype=torch.float16, device='cuda')\n",
    "\n",
    "init_pts2 = torch.tensor([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.5, 0.5, 0.2],\n",
    "    [ 0.5,-0.5, 0.3],\n",
    "    [ 1.0, 0.0, 0.0]\n",
    "], dtype=torch.float16, device='cuda')\n",
    "\n",
    "bez1 = BezierCurve(init_pts1, thickness=0.05, overlap=0.9, arc_samples=300, device=device)\n",
    "bez2 = BezierCurve(init_pts2, thickness=0.05, overlap=0.9, arc_samples=300, device=device)\n",
    "\n",
    "# 4) sample curve\n",
    "means1, thicknesses1 = bez1()\n",
    "means2, thicknesses2 = bez2()\n",
    "viewmat = w2c.to(dtype=means1.dtype)\n",
    "K = K.to(dtype=means1.dtype)\n",
    "# 5) render all spheres along the curve\n",
    "means = torch.cat([means1, means2], dim=0)  # (N,3)\n",
    "thicknesses = torch.cat([thicknesses1, thicknesses2], dim=0)  # (N,)\n",
    "means = means.to(device)\n",
    "thicknesses = thicknesses.to(device)\n",
    "\n",
    "means = repeat(means, 'n c -> b n c', b=batch_size)  # (B,N,3)\n",
    "thicknesses = repeat(thicknesses, 'n -> b n', b=batch_size)  # (B,N)\n",
    "\n",
    "print(\"means.shape\", means.shape)\n",
    "print(\"thicknesses.shape\", thicknesses.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f8f128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "179e487d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 11.74 GiB of which 465.62 MiB is free. Including non-PyTorch memory, this process has 9.57 GiB memory in use. Of the allocated memory 9.36 GiB is allocated by PyTorch, and 49.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img_t \u001b[38;5;241m=\u001b[39m \u001b[43mrasterize_spheres\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradii_world\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthicknesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mviewmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviewmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (H,W,1)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_t.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_t\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 6) convert & show\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPFL/MA2/Visual_Intelligence/clipasso3d/source/diffrasterizer.py:73\u001b[0m, in \u001b[0;36mrasterize_spheres\u001b[0;34m(means, radii_world, viewmat, K, width, height)\u001b[0m\n\u001b[1;32m     70\u001b[0m inv_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (r_px\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)  \u001b[38;5;66;03m# avoid divide-by-zero\u001b[39;00m\n\u001b[1;32m     71\u001b[0m inv_var \u001b[38;5;241m=\u001b[39m rearrange(inv_var, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb n -> b 1 1 n 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, b\u001b[38;5;241m=\u001b[39mB, n\u001b[38;5;241m=\u001b[39mN)  \u001b[38;5;66;03m# (B,1,1,N,1)\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m m2 \u001b[38;5;241m=\u001b[39m (dx \u001b[38;5;241m*\u001b[39m dx \u001b[38;5;241m*\u001b[39m inv_var) \u001b[38;5;241m+\u001b[39m (\u001b[43mdy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m \u001b[38;5;241m*\u001b[39m inv_var)  \u001b[38;5;66;03m# (B,H,W,N,1)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m m2 \u001b[38;5;241m=\u001b[39m m2\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# -- 4. Composite Gaussian spheres into image --\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 11.74 GiB of which 465.62 MiB is free. Including non-PyTorch memory, this process has 9.57 GiB memory in use. Of the allocated memory 9.36 GiB is allocated by PyTorch, and 49.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "img_t = rasterize_spheres(\n",
    "    means=means,\n",
    "    radii_world=thicknesses,\n",
    "    viewmat=viewmat,\n",
    "    K=K,\n",
    "    width=W,\n",
    "    height=H\n",
    ")  # (H,W,1)\n",
    "\n",
    "print(\"img_t.shape\", img_t.shape)\n",
    "\n",
    "# 6) convert & show\n",
    "img_np = (img_t[...,0].cpu().detach().numpy()*255).astype(\"uint8\")\n",
    "for i in range(batch_size):\n",
    "    # show image inline in notebook\n",
    "    plt.imshow(img_np[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc44d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dsketch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
