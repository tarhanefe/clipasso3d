{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b2070a",
   "metadata": {},
   "source": [
    "### 1- Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torchvision.transforms as T\n",
    "sys.path.append(\"..\")\n",
    "from source.cliploss import Loss\n",
    "from source.beziercurve import CurveSet\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "from source.imagesampler import ImageSampler\n",
    "from source.initalizer import random_short_lines, initialize_saliency_curves\n",
    "from source.saliency import DinoSaliency\n",
    "from source.trainer import Trainer\n",
    "from types import SimpleNamespace\n",
    "torch.random.manual_seed(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2cd53b",
   "metadata": {},
   "source": [
    "### 2- Setting Important Hyperparameters of the Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ————————————————————————————————\n",
    "# Important Hyperparameters\n",
    "# ————————————————————————————————\n",
    "batch_size            = 1\n",
    "epochs                = 10\n",
    "inner_steps           = 30\n",
    "thickness             = 0.02\n",
    "learning_rate         = 0.005\n",
    "data_name             = 'bike'\n",
    "clip_conv_layer_weights= [0, 0, 1.0, 1.0, 0.0]\n",
    "clip_fc_loss_weight   = 0.1\n",
    "clip_weight           = 1.0\n",
    "clip_conv_loss        = 1.0\n",
    "n_curves              = 25\n",
    "radius                = 0.8  # how far out to place each line from center\n",
    "length                = 0.02  # how long each line is\n",
    "overlap               = 0.6\n",
    "#rgb_dir              = Path('..') / 'data' / data_name / 'rgb' / 'train'\n",
    "#worldpos_dir         = Path('..') / 'data' / data_name / 'world_pos' / 'train'\n",
    "#transforms_json       = Path('..') / 'data' / data_name / 'transforms_train.json'\n",
    "# device, image size, output dir\n",
    "device   = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "width, height = 224, 224\n",
    "save_dir = Path('training_frames')\n",
    "save_dir.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b1cf2",
   "metadata": {},
   "source": [
    "### 3- Preparing necessary configurations with the hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ————————————————————————————————\n",
    "# 1) Prepare three samplers: train / val / test\n",
    "# ————————————————————————————————\n",
    "base = Path('..') / 'data' / data_name\n",
    "\n",
    "train_sampler = ImageSampler(\n",
    "    transforms_json = str(base / 'transforms_train.json'),\n",
    "    image_dir      = str(base / 'rgb'),\n",
    "    width          = width, \n",
    "    height         = height,\n",
    "    device         = device,\n",
    ")\n",
    "val_sampler = ImageSampler(\n",
    "    transforms_json = str(base / 'transforms_val.json'),\n",
    "    image_dir      = str(base / 'rgb'),\n",
    "    width          = width, \n",
    "    height         = height,\n",
    "    device         = device,\n",
    ")\n",
    "test_sampler = ImageSampler(\n",
    "    transforms_json = str(base / 'transforms_test.json'),\n",
    "    image_dir      = str(base / 'rgb'),\n",
    "    width          = width, \n",
    "    height         = height,\n",
    "    device         = device,\n",
    ")\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 2) Build loss, rasterizer, curve-set, optimizer\n",
    "# ————————————————————————————————\n",
    "args = SimpleNamespace(\n",
    "    device               = device,\n",
    "    percep_loss          = 'none',\n",
    "    train_with_clip      = True,\n",
    "    clip_weight          = clip_weight,\n",
    "    start_clip           = 0,\n",
    "    clip_conv_loss       = clip_conv_loss,\n",
    "    clip_fc_loss_weight  = clip_fc_loss_weight,\n",
    "    clip_text_guide      = 0.0,\n",
    "    num_aug_clip         = 4,\n",
    "    augemntations        = ['affine'],\n",
    "    include_target_in_aug= False,\n",
    "    augment_both         = False,\n",
    "    clip_model_name      = 'ViT-B/32',\n",
    "    clip_conv_loss_type  = 'L2',\n",
    "    clip_conv_layer_weights = clip_conv_layer_weights,\n",
    ")\n",
    "criterion   = Loss(args).to(device)\n",
    "rasterizer  = torch.compile(rasterize_spheres)\n",
    "\n",
    "# initialize curves around the computed scene center\n",
    "center_t  = torch.tensor(train_sampler.scene_center, device=device, dtype=torch.float32)\n",
    "# 2) Build DINO saliency model\n",
    "# saliency_model = DinoSaliency(device=device, preprocess_shape=(height, width))\n",
    "\n",
    "# # 3) Initialize curves\n",
    "# curves = initialize_saliency_curves(\n",
    "#     transforms_json = transforms_json,\n",
    "#     rgb_dir          = rgb_dir,\n",
    "#     worldpos_dir     = worldpos_dir,\n",
    "#     width            = width,\n",
    "#     height           = height,\n",
    "#     saliency_model   = saliency_model,\n",
    "#     num_points       = 1000,\n",
    "#     min_distance     = 0.001,\n",
    "#     threshold        = 0.9,\n",
    "#     z_thresh         = 0.05,\n",
    "#     length           = length,\n",
    "#     n_curves         = n_curves,\n",
    "#     device           = device,\n",
    "# )  # Tensor of shape (≤n_curves, 4, 3)\n",
    "\n",
    "curves = random_short_lines(center_t, n_curves, radius, length, device)\n",
    "\n",
    "curve_set = CurveSet(\n",
    "    curves,\n",
    "    thickness   = thickness,\n",
    "    overlap     = overlap,\n",
    "    arc_samples = 300,\n",
    "    device      = device\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(curve_set.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50da89",
   "metadata": {},
   "source": [
    "### 4- Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ————————————————————————————————\n",
    "# 3) Create Trainer and run\n",
    "# ————————————————————————————————\n",
    "trainer = Trainer(\n",
    "    train_sampler = train_sampler,\n",
    "    val_sampler   = val_sampler,\n",
    "    test_sampler  = test_sampler,\n",
    "    curve_set     = curve_set,\n",
    "    rasterizer    = rasterizer,\n",
    "    criterion     = criterion,\n",
    "    optimizer     = optimizer,\n",
    "    batch_size    = batch_size,\n",
    "    inner_steps   = inner_steps,\n",
    "    epochs        = epochs,\n",
    "    width         = width,\n",
    "    height        = height,\n",
    "    save_dir      = str(save_dir),\n",
    "    eval_interval = 2,       # run val‐loss every 100 batches\n",
    "    device        = device,\n",
    "    display_plots = True,      # toggle real‐time images\n",
    ")\n",
    "\n",
    "means, thicknesses = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f04b21",
   "metadata": {},
   "source": [
    "### 5- Plotting generated curves in 3D plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "def plot_spheres_matplotlib(\n",
    "    means: np.ndarray,\n",
    "    radii: np.ndarray,\n",
    "    resolution: int = 20,\n",
    "    alpha: float = 0.6,\n",
    "    colormap: str = \"viridis\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot 3D spheres centered at `means` with given `radii`, using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        means      (N,3) numpy array of sphere centers\n",
    "        radii      (N,)  numpy array of sphere radii\n",
    "        resolution number of subdivisions in θ,ϕ (higher → smoother)\n",
    "        alpha      transparency of each sphere\n",
    "        colormap   name of a matplotlib colormap for coloring spheres\n",
    "    \"\"\"\n",
    "    # parameterize a unit sphere\n",
    "    u = np.linspace(0, 2 * np.pi, resolution)\n",
    "    v = np.linspace(0, np.pi, resolution)\n",
    "    uu, vv = np.meshgrid(u, v)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5),dpi = 600)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    N = len(means)\n",
    "\n",
    "    for i, ((x0, y0, z0), r) in enumerate(zip(means, radii)):\n",
    "        # compute sphere surface\n",
    "        x = x0 + r * np.cos(uu) * np.sin(vv)\n",
    "        y = y0 + r * np.sin(uu) * np.sin(vv)\n",
    "        z = z0 + r * np.cos(vv)\n",
    "\n",
    "        # pick a color from the colormap\n",
    "        color = cmap(i / max(1, N - 1))  # RGBA tuple\n",
    "        # now build a (res,res,4) array of that color\n",
    "        fc = np.broadcast_to(np.array(color)[None, None, :], x.shape + (4,))\n",
    "\n",
    "        ax.plot_surface(\n",
    "            x, y, z,\n",
    "            rstride=1, cstride=1,\n",
    "            facecolors=fc,\n",
    "            edgecolor='k',    # draw black edges\n",
    "            linewidth=0.2,    # thin lines\n",
    "            shade=True,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "    # equal aspect ratio\n",
    "    xyz = np.vstack([means + radii[:, None], means - radii[:, None]])\n",
    "    x_limits = (xyz[:, 0].min(), xyz[:, 0].max())\n",
    "    y_limits = (xyz[:, 1].min(), xyz[:, 1].max())\n",
    "    z_limits = (xyz[:, 2].min(), xyz[:, 2].max())\n",
    "    max_range = np.array([\n",
    "        x_limits[1] - x_limits[0],\n",
    "        y_limits[1] - y_limits[0],\n",
    "        z_limits[1] - z_limits[0],\n",
    "    ]).max() / 2.0\n",
    "\n",
    "    mid_x = np.mean(x_limits)\n",
    "    mid_y = np.mean(y_limits)\n",
    "    mid_z = np.mean(z_limits)\n",
    "\n",
    "    #ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    #ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    #ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"3D_spheres_plot.png\", dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "means_np = trainer.means.detach().cpu().numpy()\n",
    "radii_np = trainer.thicknesses.detach().cpu().numpy()\n",
    "plot_spheres_matplotlib(means_np, radii_np*2, resolution=5, alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f63e1",
   "metadata": {},
   "source": [
    "### 6- Creating a GIF with training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "# Gather and sort saved frames\n",
    "frame_paths = sorted(save_dir.glob(\"batch_*.png\"))\n",
    "frames = [PILImage.open(p) for p in frame_paths]\n",
    "\n",
    "# Save GIF\n",
    "gif_path = \"training_evolution.gif\"\n",
    "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=50, loop=0)\n",
    "print(f\"GIF saved to {gif_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c984c",
   "metadata": {},
   "source": [
    "### 7- Cell for saving and loading means and thicknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save means, thicknesses, scene center, and K\n",
    "torch.save({'means': trainer.means, 'thicknesses': trainer.thicknesses, 'scene_center': trainer.train_sampler.scene_center, 'K':trainer.train_sampler.K}, 'tensors.pt')\n",
    "# Load the tensors \n",
    "data = torch.load('tensors.pt')\n",
    "means = data['means']\n",
    "thicknesses = data['thicknesses']\n",
    "scene_center = data['scene_center']\n",
    "K = data['K']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61186a0e",
   "metadata": {},
   "source": [
    "### 8- Creating a GIF that rotates around the scene center of the optimized visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "torch.cuda.empty_cache()\n",
    "def look_at(eye: torch.Tensor,\n",
    "            center: torch.Tensor,\n",
    "            up:    torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build a world→camera 4×4 view matrix given an eye position, a look-at center, and an up vector.\n",
    "    \"\"\"\n",
    "    z = (eye - center)\n",
    "    z = z / z.norm(dim=0, keepdim=True)\n",
    "    x = torch.cross(up, z)\n",
    "    x = x / x.norm(dim=0, keepdim=True)\n",
    "    y = torch.cross(z, x)\n",
    "    R = torch.stack([x, y, z], dim=0)      # 3×3 rotation\n",
    "    T = -R @ eye.view(3,1)                 # 3×1 translation\n",
    "    view = torch.eye(4, device=eye.device, dtype=eye.dtype)\n",
    "    view[:3,:3] = R\n",
    "    view[:3, 3] = T.squeeze()\n",
    "    return view\n",
    "\n",
    "def render_semihelical_gif(\n",
    "    means:          torch.Tensor,           # (N,3) sphere centers\n",
    "    radii:          torch.Tensor|float,\n",
    "    scene_center:   torch.Tensor,           # (3,)\n",
    "    scene_radius:   float,\n",
    "    K:              torch.Tensor,           # 3×3 intrinsics\n",
    "    width:          int,\n",
    "    height:         int,\n",
    "    fps:            int     = 15,           # playback frames per second\n",
    "    rotation_time:  float   = 5.0,          # seconds to go from +X→+Z\n",
    "    revolutions:    float   = 2.0,          # how many twists around Y-axis\n",
    "    up:             torch.Tensor = torch.tensor([0.,0, 1]),\n",
    "    output_path:    str     = \"semihelical.gif\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Renders a helical camera path on the upper hemisphere of radius `scene_radius`,\n",
    "    starting at scene_center + (scene_radius,0,0) and ending at\n",
    "    scene_center + (0,0,scene_radius), twisting `revolutions` times around Y.\n",
    "    Produces a looping GIF at `fps` for a total duration of rotation_time.\n",
    "    \"\"\"\n",
    "    device = 'cpu'\n",
    "    device = means.device\n",
    "    center = scene_center.to(device=device, dtype=means.dtype)\n",
    "    up_vec = up.to(device=device, dtype=means.dtype)\n",
    "\n",
    "    n_frames   = int(round(fps * rotation_time))\n",
    "    duration_ms = int(round(1000.0 / fps))\n",
    "\n",
    "    frames = []\n",
    "    for i in range(n_frames):\n",
    "        t   = i / (n_frames - 1)                # from 0 → 1\n",
    "        phi = t * (math.pi / 2)                # elevation from 0 → 90°\n",
    "        theta = t * (2 * math.pi * revolutions)  # azimuthal twist\n",
    "\n",
    "        # Parametric point on hemisphere surface (Z is up)\n",
    "        x = center[0] + scene_radius * math.cos(phi) * math.cos(theta)\n",
    "        y = center[1] + scene_radius * math.cos(phi) * math.sin(theta)\n",
    "        z = center[2] + scene_radius * math.sin(phi)\n",
    "        cam_pos = torch.tensor([x, y, z], device=device, dtype=means.dtype)\n",
    "\n",
    "        V = look_at(cam_pos, center, up_vec)  \n",
    "        alpha = rasterize_spheres(means, radii, V, K, width, height)  # (H,W,1)\n",
    "        a_np  = (alpha[...,0].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        rgb   = np.stack([a_np]*3, axis=-1)     # gray → RGB\n",
    "        frames.append(Image.fromarray(rgb))\n",
    "\n",
    "    # Save as a looping GIF\n",
    "    frames[0].save(\n",
    "        output_path,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=duration_ms,\n",
    "        loop=0\n",
    "    )\n",
    "    print(f\"Saved {output_path}: {n_frames} frames, {fps} FPS, {revolutions} revolutions.\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# --- example usage ---\n",
    "# Example data\n",
    "means = trainer.means\n",
    "N = means.shape[0]\n",
    "radii = thickness                             # uniform radius\n",
    "scene_center = torch.tensor(trainer.train_sampler.scene_center)\n",
    "scene_radius = 15\n",
    "\n",
    "W, H = 224, 224\n",
    "K = trainer.train_sampler.K\n",
    "\n",
    "render_semihelical_gif(\n",
    "    means, radii, scene_center, scene_radius,\n",
    "    K, W, H,\n",
    "    fps=120,\n",
    "    rotation_time=6.0,\n",
    "    revolutions=3.0,\n",
    "    output_path=\"semihelical.gif\"\n",
    ")\n",
    "print(means)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vimm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
