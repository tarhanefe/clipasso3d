{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torchvision.transforms as T\n",
    "from source.cliploss import Loss\n",
    "from source.beziercurve import CurveSet\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "from types import SimpleNamespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b27dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (for 3d projection)\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import torchvision.transforms as T\n",
    "sys.path.append(\"..\")\n",
    "from source.utils import load_scene\n",
    "\n",
    "class ImageSampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        transforms_json: str,\n",
    "        image_dir: str,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        total_iters: int,\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        # 1. Load scene metadata\n",
    "        file_paths, c2w_all, K = load_scene(transforms_json, width, height, device)\n",
    "        self.device = device\n",
    "        self.K = K.to(device)\n",
    "\n",
    "        # 2. Store camera-to-world matrices\n",
    "        self.c2w_all = c2w_all.to(device)  # (N,4,4)\n",
    "\n",
    "        # 2a. Extract camera origins P and viewing directions N\n",
    "        P = self.c2w_all[:, :3, 3]              # (N,3)\n",
    "        N = -self.c2w_all[:, :3, 2]             # (N,3)\n",
    "\n",
    "        # 2b. Compute scene center by least-squares intersection of camera rays\n",
    "        # Solve: sum_i (I - N_i N_i^T) X = sum_i (I - N_i N_i^T) P_i\n",
    "        I = torch.eye(3, device=P.device, dtype=P.dtype)\n",
    "        A = torch.zeros((3, 3), device=P.device, dtype=P.dtype)\n",
    "        b = torch.zeros((3,),    device=P.device, dtype=P.dtype)\n",
    "        for i in range(P.shape[0]):\n",
    "            n_i = N[i].unsqueeze(1)             # (3,1)\n",
    "            M_i = I - n_i @ n_i.T               # (3,3)\n",
    "            A += M_i\n",
    "            b += (M_i @ P[i])\n",
    "        # Solve linear system\n",
    "        center = torch.linalg.solve(A, b)       # (3,)\n",
    "        self.scene_center = center.cpu().numpy()\n",
    "\n",
    "        # 2c. Precompute world-to-camera for rendering\n",
    "        self.w2c_all = torch.linalg.inv(self.c2w_all)\n",
    "\n",
    "        # 3. Preload & resize all images\n",
    "        to_tensor = T.ToTensor()\n",
    "        self.images = []\n",
    "        for fp in file_paths:\n",
    "            cleaned = fp.lstrip(\"./\")\n",
    "            rel_dir, stem = os.path.split(cleaned)\n",
    "            base_dir = os.path.join(image_dir, rel_dir)\n",
    "\n",
    "            # try common extensions\n",
    "            for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "                candidate = os.path.join(base_dir, stem + ext)\n",
    "                if os.path.exists(candidate):\n",
    "                    img = Image.open(candidate).convert(\"RGB\")\n",
    "                    break\n",
    "            else:\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Could not find any of {stem} in {base_dir} with .png/.jpg/.jpeg\"\n",
    "                )\n",
    "\n",
    "            t = to_tensor(img).unsqueeze(0).to(device)\n",
    "            t = torch.nn.functional.interpolate(\n",
    "                t, size=(height, width), mode=\"bilinear\"\n",
    "            )\n",
    "            self.images.append(t)\n",
    "\n",
    "        # 4. Build fixed schedule of length total_iters\n",
    "        num_images = len(self.images)\n",
    "        repeats = math.ceil(total_iters / num_images)\n",
    "        schedule = torch.arange(num_images, device=device).repeat_interleave(repeats)\n",
    "        self.schedule = schedule[:total_iters]\n",
    "\n",
    "    def sample(self, it: int):\n",
    "        \"\"\"\n",
    "        On iteration `it` return:\n",
    "          - target_rgb: (1,3,H,W)\n",
    "          - K:         (3,3)\n",
    "          - w2c:       (4,4)\n",
    "        \"\"\"\n",
    "        idx = int(self.schedule[it])\n",
    "        return self.images[idx], self.K, self.w2c_all[idx]\n",
    "\n",
    "    def plot_camera_poses(\n",
    "        self,\n",
    "        arrow_length: float = 0.5,\n",
    "        cube_size: float = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plot 3D camera positions with view normals and optional cube.\n",
    "\n",
    "        Args:\n",
    "            arrow_length: arrow length for view normals.\n",
    "            cube_size: if set, draws a cube of side cube_size whose center sits\n",
    "                       at the computed scene_center.\n",
    "        Returns:\n",
    "            fig, ax: Matplotlib Figure and 3D Axes.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Plot camera origins\n",
    "        pos = self.c2w_all[:, :3, 3].cpu().numpy()\n",
    "        ax.scatter(pos[:,0], pos[:,1], pos[:,2], c='red', s=30, label='Cameras')\n",
    "\n",
    "        # Plot view normals\n",
    "        normals = -self.c2w_all[:, :3, 2].cpu().numpy()\n",
    "        for p, n in zip(pos, normals):\n",
    "            ax.quiver(\n",
    "                p[0], p[1], p[2],\n",
    "                n[0], n[1], n[2],\n",
    "                length=arrow_length, normalize=True,\n",
    "                color='blue', linewidth=1\n",
    "            )\n",
    "\n",
    "        # Draw cube at scene_center\n",
    "        if cube_size is not None:\n",
    "            cx, cy, cz = self.scene_center\n",
    "            half = cube_size / 2.0\n",
    "            vertices = np.array([\n",
    "                [cx-half, cy-half, cz-half],\n",
    "                [cx+half, cy-half, cz-half],\n",
    "                [cx+half, cy+half, cz-half],\n",
    "                [cx-half, cy+half, cz-half],\n",
    "                [cx-half, cy-half, cz+half],\n",
    "                [cx+half, cy-half, cz+half],\n",
    "                [cx+half, cy+half, cz+half],\n",
    "                [cx-half, cy+half, cz+half],\n",
    "            ])\n",
    "            faces = [\n",
    "                [0,1,2,3], [4,5,6,7],\n",
    "                [0,1,5,4], [1,2,6,5],\n",
    "                [2,3,7,6], [3,0,4,7]\n",
    "            ]\n",
    "            face_verts = [[vertices[idx] for idx in face] for face in faces]\n",
    "            poly = Poly3DCollection(face_verts, alpha=0.3, facecolor='cyan', edgecolor='k', label='Object')\n",
    "            ax.add_collection3d(poly)\n",
    "\n",
    "        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "        ax.set_title('Scene Setup')\n",
    "        ax.legend()\n",
    "\n",
    "        # Equal aspect\n",
    "        max_range = (pos.max(axis=0) - pos.min(axis=0)).max() / 2.0\n",
    "        mid = pos.mean(axis=0)\n",
    "        ax.set_xlim(mid[0]-max_range, mid[0]+max_range)\n",
    "        ax.set_ylim(mid[1]-max_range, mid[1]+max_range)\n",
    "        ax.set_zlim(mid[2]-max_range, mid[2]+max_range)\n",
    "\n",
    "        plt.show()\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "width, height = 224, 224\n",
    "batch_size = 1\n",
    "epochs = 400\n",
    "inner_steps = 30\n",
    "thickness = 0.01\n",
    "learning_rate = 0.001\n",
    "save_dir = Path('training_frames')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4982d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare data sampler for a single scene ---\n",
    "data_name = 'chair'\n",
    "transforms_json = '../data/{}/transforms_train.json'.format(data_name)\n",
    "image_dir = '../data/{}'.format(data_name)\n",
    "sampler = ImageSampler(\n",
    "    transforms_json=transforms_json,\n",
    "    image_dir=image_dir,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    total_iters=0,  # unused in random sampling\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Prepare loss and rasterizer ---\n",
    "args = SimpleNamespace(\n",
    "    device=device,\n",
    "    percep_loss='none',\n",
    "    train_with_clip=True,\n",
    "    clip_weight=1.0,\n",
    "    start_clip=0,\n",
    "    clip_conv_loss=1,\n",
    "    clip_fc_loss_weight=0.1,\n",
    "    clip_text_guide=0.0,\n",
    "    num_aug_clip=4,\n",
    "    augemntations=['affine'],\n",
    "    include_target_in_aug=False,\n",
    "    augment_both=False,\n",
    "    clip_model_name='ViT-B/32',\n",
    "    clip_conv_loss_type='L2',\n",
    "    clip_conv_layer_weights=[0, 0, 1.0, 1.0, 0.0]\n",
    ")\n",
    "criterion = Loss(args).to(device)\n",
    "rasterizer = torch.compile(rasterize_spheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize curves as short lines at random locations on a sphere ---\n",
    "def random_short_lines(center: torch.Tensor,\n",
    "                       n_curves: int,\n",
    "                       radius: float,\n",
    "                       length: float,\n",
    "                       device: str):\n",
    "    \"\"\"\n",
    "    center: (3,) origin of the sphere\n",
    "    n_curves: how many line‐curves to make\n",
    "    radius:  how far from center to place each line\n",
    "    length:  total length of each line segment\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for _ in range(n_curves):\n",
    "        # 1) Pick a random point ON the sphere\n",
    "        dir_loc = torch.randn(3, device=device)\n",
    "        dir_loc = dir_loc / dir_loc.norm()\n",
    "        loc = center + radius * dir_loc       # (3,)\n",
    "\n",
    "        # 2) Pick a random line direction orthogonal to dir_loc\n",
    "        dir_line = torch.randn(3, device=device)\n",
    "        dir_line = dir_line - (dir_line @ dir_loc) * dir_loc\n",
    "        dir_line = dir_line / dir_line.norm()\n",
    "\n",
    "        # 3) Build 4 control points along that line of total length `length`\n",
    "        offsets = torch.tensor([-0.5, -0.1667, 0.1667, 0.5],\n",
    "                               device=device) * length  # (4,)\n",
    "        ctrl_pts = loc[None] + offsets[:, None] * dir_line[None]  # (4,3)\n",
    "\n",
    "        lines.append(ctrl_pts)\n",
    "    return lines\n",
    "\n",
    "# Convert numpy center to torch\n",
    "center_t = torch.tensor(sampler.scene_center,\n",
    "                        device=device, dtype=torch.float32)\n",
    "\n",
    "# Parameters\n",
    "n_curves = 20\n",
    "radius   = 0.7    # how far out to place each line from center\n",
    "length   = 0.01    # how long each line is\n",
    "\n",
    "# Generate\n",
    "init_pts = random_short_lines(center_t, n_curves, radius, length, device)\n",
    "\n",
    "# Create & optimize\n",
    "curve_set = CurveSet(init_pts,\n",
    "                     thickness=thickness,\n",
    "                     overlap=0.6,\n",
    "                     arc_samples=300,\n",
    "                     device=device).to(device)\n",
    "optimizer = optim.Adam(curve_set.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup display as 1×2 subplots ---\n",
    "plt.ioff()\n",
    "fig, (ax_render, ax_target) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# placeholder for the render\n",
    "im_render = ax_render.imshow(\n",
    "    torch.zeros((height, width, 3), dtype=torch.float32).numpy(),\n",
    "    vmin=0, vmax=1\n",
    ")\n",
    "ax_render.set_title(\"Render\")\n",
    "ax_render.axis('off')\n",
    "\n",
    "# placeholder for the target\n",
    "# assume the very first sample shows its target\n",
    "first_target = sampler.images[0][0].permute(1,2,0).cpu().numpy()\n",
    "im_target = ax_target.imshow(first_target, vmin=0, vmax=1)\n",
    "ax_target.set_title(\"Target\")\n",
    "ax_target.axis('off')\n",
    "\n",
    "# --- Training loop (multi‐step per batch) ---\n",
    "N_views          = len(sampler.images)\n",
    "updates_per_epoch= math.ceil(N_views / batch_size)\n",
    "total_batches    = updates_per_epoch * epochs\n",
    "\n",
    "for batch_idx in range(total_batches):\n",
    "    # 1) sample a fresh batch of views\n",
    "    batch_data = []\n",
    "    for _ in range(batch_size):\n",
    "        v_idx = random.randrange(N_views)\n",
    "        batch_data.append((\n",
    "            sampler.images[v_idx],      # target_rgb (1,3,H,W)\n",
    "            sampler.K,                  # K\n",
    "            sampler.w2c_all[v_idx]      # world‐to‐camera\n",
    "        ))\n",
    "\n",
    "    # 2) take `inner_steps` gradient updates on this same batch\n",
    "    for inner in range(inner_steps):\n",
    "        optimizer.zero_grad()\n",
    "        losses = []\n",
    "        for target_rgb, K, w2c in batch_data:\n",
    "            means, thicknesses = curve_set()\n",
    "            img = rasterizer(means, thicknesses, w2c, K, width, height)\n",
    "            img = img.permute(2,0,1).unsqueeze(0).repeat(1,3,1,1)\n",
    "            it = batch_idx * inner_steps + inner\n",
    "            losses.append(criterion(img, target_rgb, it))\n",
    "        loss = torch.stack(losses).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # after inner steps, display both render and its corresponding target\n",
    "    # take the *last* rendered img and the *first* target in batch_data as example\n",
    "    render_np = img[0].permute(1,2,0).detach().cpu().numpy()\n",
    "    target_np = batch_data[0][0][0].permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    im_render.set_data(render_np)\n",
    "    im_target.set_data(target_np)\n",
    "\n",
    "    ax_render.set_title(\n",
    "        f\"Render (Batch {batch_idx}/{total_batches})\\nLoss {loss.item():.4f}\"\n",
    "    )\n",
    "    ax_target.set_title(\"Target\")\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.savefig(save_dir / f'batch_{batch_idx:04d}.png',\n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "def plot_spheres_matplotlib(\n",
    "    means: np.ndarray,\n",
    "    radii: np.ndarray,\n",
    "    resolution: int = 20,\n",
    "    alpha: float = 0.6,\n",
    "    colormap: str = \"viridis\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot 3D spheres centered at `means` with given `radii`, using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        means      (N,3) numpy array of sphere centers\n",
    "        radii      (N,)  numpy array of sphere radii\n",
    "        resolution number of subdivisions in θ,ϕ (higher → smoother)\n",
    "        alpha      transparency of each sphere\n",
    "        colormap   name of a matplotlib colormap for coloring spheres\n",
    "    \"\"\"\n",
    "    # parameterize a unit sphere\n",
    "    u = np.linspace(0, 2 * np.pi, resolution)\n",
    "    v = np.linspace(0, np.pi, resolution)\n",
    "    uu, vv = np.meshgrid(u, v)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5),dpi = 600)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    N = len(means)\n",
    "\n",
    "    for i, ((x0, y0, z0), r) in enumerate(zip(means, radii)):\n",
    "        # compute sphere surface\n",
    "        x = x0 + r * np.cos(uu) * np.sin(vv)\n",
    "        y = y0 + r * np.sin(uu) * np.sin(vv)\n",
    "        z = z0 + r * np.cos(vv)\n",
    "\n",
    "        # pick a color from the colormap\n",
    "        color = cmap(i / max(1, N - 1))  # RGBA tuple\n",
    "        # now build a (res,res,4) array of that color\n",
    "        fc = np.broadcast_to(np.array(color)[None, None, :], x.shape + (4,))\n",
    "\n",
    "        ax.plot_surface(\n",
    "            x, y, z,\n",
    "            rstride=1, cstride=1,\n",
    "            facecolors=fc,\n",
    "            edgecolor='k',    # draw black edges\n",
    "            linewidth=0.2,    # thin lines\n",
    "            shade=True,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "    # equal aspect ratio\n",
    "    xyz = np.vstack([means + radii[:, None], means - radii[:, None]])\n",
    "    x_limits = (xyz[:, 0].min(), xyz[:, 0].max())\n",
    "    y_limits = (xyz[:, 1].min(), xyz[:, 1].max())\n",
    "    z_limits = (xyz[:, 2].min(), xyz[:, 2].max())\n",
    "    max_range = np.array([\n",
    "        x_limits[1] - x_limits[0],\n",
    "        y_limits[1] - y_limits[0],\n",
    "        z_limits[1] - z_limits[0],\n",
    "    ]).max() / 2.0\n",
    "\n",
    "    mid_x = np.mean(x_limits)\n",
    "    mid_y = np.mean(y_limits)\n",
    "    mid_z = np.mean(z_limits)\n",
    "\n",
    "    #ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    #ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    #ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"3D_spheres_plot.png\", dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_np = means.detach().cpu().numpy()\n",
    "radii_np = thicknesses.detach().cpu().numpy()\n",
    "plot_spheres_matplotlib(means_np, radii_np*2, resolution=5, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "# Gather and sort saved frames\n",
    "frame_paths = sorted(save_dir.glob(\"batch_*.png\"))\n",
    "frames = [PILImage.open(p) for p in frame_paths]\n",
    "\n",
    "# Save GIF\n",
    "gif_path = \"training_evolution.gif\"\n",
    "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=50, loop=0)\n",
    "print(f\"GIF saved to {gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372285b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vimm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
