{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c2c891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss breakdown:\n",
      "  clip_conv_loss: 0.0000\n",
      "  clip_conv_loss_layer2: 0.0206\n",
      "  clip_conv_loss_layer3: 0.0124\n",
      "  fc: 0.0008\n",
      "Total weighted loss: 0.0337\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "\n",
    "# Add the source folder to sys.path\n",
    "sys.path.append('../source')\n",
    "\n",
    "# Import the top-level Loss class\n",
    "from cliploss import Loss\n",
    "\n",
    "# Define dummy args with both semantic and geometric loss disabled/enabled as needed\n",
    "args = SimpleNamespace(\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    percep_loss=\"none\",                  # no perceptual loss like LPIPS\n",
    "    train_with_clip=False,               # enable CLIP loss\n",
    "    clip_weight=0,                    # weight for semantic CLIP loss\n",
    "    start_clip=0,                       # start CLIP loss immediately\n",
    "    clip_conv_loss=1,              # disable geometric loss for this test\n",
    "    clip_fc_loss_weight=0.1,           # weight for fc in conv loss (irrelevant since disabled)\n",
    "    clip_text_guide=0.0,               # unused here\n",
    "    num_aug_clip=4,                    # number of augmentations\n",
    "    augemntations=[\"affine\"],          # apply affine augmentation\n",
    "    include_target_in_aug=False,       # only augment sketch\n",
    "    augment_both=False,\n",
    "    clip_model_name=\"ViT-B/32\",\n",
    "    clip_conv_loss_type=\"L2\",          # not used in this config\n",
    "    clip_conv_layer_weights=[0, 0, 1.0, 1.0, 0],  # not used unless clip_conv_loss=True\n",
    ")\n",
    "\n",
    "# Create dummy sketch and target tensors\n",
    "def get_dummy_image(size=(224, 224)):\n",
    "    return torch.rand(1, 3, *size)\n",
    "\n",
    "sketch = get_dummy_image().to(args.device)\n",
    "target = get_dummy_image().to(args.device)\n",
    "\n",
    "# Instantiate and run the combined Loss\n",
    "loss_fn = Loss(args).to(args.device)\n",
    "losses_dict = loss_fn(sketch, target, epoch=100, mode=\"train\")\n",
    "\n",
    "# Compute total loss from weighted components\n",
    "final_loss = sum(losses_dict.values())\n",
    "\n",
    "# Print results\n",
    "print(\"Loss breakdown:\")\n",
    "for name, val in losses_dict.items():\n",
    "    print(f\"  {name}: {val.item():.4f}\")\n",
    "print(f\"Total weighted loss: {final_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cca59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vimm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
