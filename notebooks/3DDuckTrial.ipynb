{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e1e365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd8702ff250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torchvision.transforms as T\n",
    "from source.cliploss import Loss\n",
    "from source.beziercurve import CurveSet\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "from source.imagesampler import ImageSampler\n",
    "from source.initalizer import random_short_lines\n",
    "from source.trainer import Trainer\n",
    "from types import SimpleNamespace\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important Hyperparameters\n",
    "batch_size = 1\n",
    "epochs = 400\n",
    "inner_steps = 100\n",
    "thickness = 0.03\n",
    "learning_rate = 0.001\n",
    "data_name = 'duck'\n",
    "clip_conv_layer_weights=[0, 0, 1.0, 1.0, 0.0]\n",
    "clip_fc_loss_weight=0.1\n",
    "clip_weight=1.0\n",
    "clip_conv_loss=1.0\n",
    "n_curves = 20\n",
    "radius   = 0.7    # how far out to place each line from center\n",
    "length   = 0.01    # how long each line is\n",
    "overlap = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "width, height = 224, 224\n",
    "save_dir = Path('training_frames')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "# --- Prepare data sampler for a single scene ---\n",
    "transforms_json = '../data/{}/transforms_train.json'.format(data_name)\n",
    "image_dir = '../data/{}/rgb'.format(data_name)\n",
    "sampler = ImageSampler(\n",
    "    transforms_json=transforms_json,\n",
    "    image_dir=image_dir,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    total_iters=0,  # unused in random sampling\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# --- Prepare loss and rasterizer ---\n",
    "args = SimpleNamespace(\n",
    "    device=device,\n",
    "    percep_loss='none',\n",
    "    train_with_clip=True,\n",
    "    clip_weight=clip_weight,\n",
    "    start_clip=0,\n",
    "    clip_conv_loss=clip_conv_loss,\n",
    "    clip_fc_loss_weight=clip_fc_loss_weight,\n",
    "    clip_text_guide=0.0,\n",
    "    num_aug_clip=4,\n",
    "    augemntations=['affine'],\n",
    "    include_target_in_aug=False,\n",
    "    augment_both=False,\n",
    "    clip_model_name='ViT-B/32',\n",
    "    clip_conv_loss_type='L2',\n",
    "    clip_conv_layer_weights=clip_conv_layer_weights\n",
    ")\n",
    "criterion = Loss(args).to(device)\n",
    "rasterizer = torch.compile(rasterize_spheres)\n",
    "center_t = torch.tensor(sampler.scene_center,\n",
    "                        device=device, dtype=torch.float32)\n",
    "init_pts = random_short_lines(center_t, n_curves, radius, length, device)\n",
    "curve_set = CurveSet(init_pts,\n",
    "                     thickness=thickness,\n",
    "                     overlap=overlap,\n",
    "                     arc_samples=300,\n",
    "                     device=device).to(device)\n",
    "optimizer = optim.Adam(curve_set.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    sampler,\n",
    "    curve_set,\n",
    "    rasterizer,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    batch_size=batch_size,\n",
    "    inner_steps=inner_steps,\n",
    "    epochs=epochs,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    save_dir=save_dir,\n",
    "    display_plots=True\n",
    ")\n",
    "means, thicknesses = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "\n",
    "# ————————————————————————————————\n",
    "# Important Hyperparameters\n",
    "# ————————————————————————————————\n",
    "batch_size            = 1\n",
    "epochs                = 400\n",
    "inner_steps           = 100\n",
    "thickness             = 0.03\n",
    "learning_rate         = 0.001\n",
    "data_name             = 'duck'\n",
    "clip_conv_layer_weights= [0, 0, 1.0, 1.0, 0.0]\n",
    "clip_fc_loss_weight   = 0.1\n",
    "clip_weight           = 1.0\n",
    "clip_conv_loss        = 1.0\n",
    "n_curves              = 20\n",
    "radius                = 0.7   # how far out to place each line from center\n",
    "length                = 0.01  # how long each line is\n",
    "overlap               = 0.6\n",
    "\n",
    "# device, image size, output dir\n",
    "device   = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "width, height = 224, 224\n",
    "save_dir = Path('training_frames')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 1) Prepare three samplers: train / val / test\n",
    "# ————————————————————————————————\n",
    "base = Path('..') / 'data' / data_name\n",
    "train_sampler = ImageSampler(\n",
    "    transforms_json = str(base / 'transforms_train.json'),\n",
    "    image_dir      = str(base / 'rgb' / 'train'),\n",
    "    width, height  = width, height,\n",
    "    device         = device,\n",
    ")\n",
    "val_sampler = ImageSampler(\n",
    "    transforms_json = str(base / 'transforms_val.json'),\n",
    "    image_dir      = str(base / 'rgb' / 'val'),\n",
    "    width, height  = width, height,\n",
    "    device         = device,\n",
    ")\n",
    "test_sampler = ImageSampler(\n",
    "    transforms_json = str(base / 'transforms_test.json'),\n",
    "    image_dir      = str(base / 'rgb' / 'test'),\n",
    "    width, height  = width, height,\n",
    "    device         = device,\n",
    ")\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 2) Build loss, rasterizer, curve-set, optimizer\n",
    "# ————————————————————————————————\n",
    "args = SimpleNamespace(\n",
    "    device               = device,\n",
    "    percep_loss          = 'none',\n",
    "    train_with_clip      = True,\n",
    "    clip_weight          = clip_weight,\n",
    "    start_clip           = 0,\n",
    "    clip_conv_loss       = clip_conv_loss,\n",
    "    clip_fc_loss_weight  = clip_fc_loss_weight,\n",
    "    clip_text_guide      = 0.0,\n",
    "    num_aug_clip         = 4,\n",
    "    augmentations        = ['affine'],\n",
    "    include_target_in_aug= False,\n",
    "    augment_both         = False,\n",
    "    clip_model_name      = 'ViT-B/32',\n",
    "    clip_conv_loss_type  = 'L2',\n",
    "    clip_conv_layer_weights = clip_conv_layer_weights,\n",
    ")\n",
    "criterion   = Loss(args).to(device)\n",
    "rasterizer  = torch.compile(rasterize_spheres)\n",
    "\n",
    "# initialize curves around the computed scene center\n",
    "center_t  = torch.tensor(train_sampler.scene_center, device=device, dtype=torch.float32)\n",
    "init_pts  = random_short_lines(center_t, n_curves, radius, length, device)\n",
    "curve_set = CurveSet(\n",
    "    init_pts,\n",
    "    thickness   = thickness,\n",
    "    overlap     = overlap,\n",
    "    arc_samples = 300,\n",
    "    device      = device\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(curve_set.parameters(), lr=learning_rate)\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 3) Create Trainer and run\n",
    "# ————————————————————————————————\n",
    "trainer = Trainer(\n",
    "    train_sampler = train_sampler,\n",
    "    val_sampler   = val_sampler,\n",
    "    test_sampler  = test_sampler,\n",
    "    curve_set     = curve_set,\n",
    "    rasterizer    = rasterizer,\n",
    "    criterion     = criterion,\n",
    "    optimizer     = optimizer,\n",
    "    batch_size    = batch_size,\n",
    "    inner_steps   = inner_steps,\n",
    "    epochs        = epochs,\n",
    "    width         = width,\n",
    "    height        = height,\n",
    "    save_dir      = str(save_dir),\n",
    "    eval_interval = 100,       # run val‐loss every 100 batches\n",
    "    device        = device,\n",
    "    display_plots = True,      # toggle real‐time images\n",
    ")\n",
    "\n",
    "means, thicknesses = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "def plot_spheres_matplotlib(\n",
    "    means: np.ndarray,\n",
    "    radii: np.ndarray,\n",
    "    resolution: int = 20,\n",
    "    alpha: float = 0.6,\n",
    "    colormap: str = \"viridis\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot 3D spheres centered at `means` with given `radii`, using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        means      (N,3) numpy array of sphere centers\n",
    "        radii      (N,)  numpy array of sphere radii\n",
    "        resolution number of subdivisions in θ,ϕ (higher → smoother)\n",
    "        alpha      transparency of each sphere\n",
    "        colormap   name of a matplotlib colormap for coloring spheres\n",
    "    \"\"\"\n",
    "    # parameterize a unit sphere\n",
    "    u = np.linspace(0, 2 * np.pi, resolution)\n",
    "    v = np.linspace(0, np.pi, resolution)\n",
    "    uu, vv = np.meshgrid(u, v)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5),dpi = 600)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    N = len(means)\n",
    "\n",
    "    for i, ((x0, y0, z0), r) in enumerate(zip(means, radii)):\n",
    "        # compute sphere surface\n",
    "        x = x0 + r * np.cos(uu) * np.sin(vv)\n",
    "        y = y0 + r * np.sin(uu) * np.sin(vv)\n",
    "        z = z0 + r * np.cos(vv)\n",
    "\n",
    "        # pick a color from the colormap\n",
    "        color = cmap(i / max(1, N - 1))  # RGBA tuple\n",
    "        # now build a (res,res,4) array of that color\n",
    "        fc = np.broadcast_to(np.array(color)[None, None, :], x.shape + (4,))\n",
    "\n",
    "        ax.plot_surface(\n",
    "            x, y, z,\n",
    "            rstride=1, cstride=1,\n",
    "            facecolors=fc,\n",
    "            edgecolor='k',    # draw black edges\n",
    "            linewidth=0.2,    # thin lines\n",
    "            shade=True,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "    # equal aspect ratio\n",
    "    xyz = np.vstack([means + radii[:, None], means - radii[:, None]])\n",
    "    x_limits = (xyz[:, 0].min(), xyz[:, 0].max())\n",
    "    y_limits = (xyz[:, 1].min(), xyz[:, 1].max())\n",
    "    z_limits = (xyz[:, 2].min(), xyz[:, 2].max())\n",
    "    max_range = np.array([\n",
    "        x_limits[1] - x_limits[0],\n",
    "        y_limits[1] - y_limits[0],\n",
    "        z_limits[1] - z_limits[0],\n",
    "    ]).max() / 2.0\n",
    "\n",
    "    mid_x = np.mean(x_limits)\n",
    "    mid_y = np.mean(y_limits)\n",
    "    mid_z = np.mean(z_limits)\n",
    "\n",
    "    #ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    #ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    #ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"3D_spheres_plot.png\", dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_np = trainer.means.detach().cpu().numpy()\n",
    "radii_np = trainer.thicknesses.detach().cpu().numpy()\n",
    "plot_spheres_matplotlib(means_np, radii_np*2, resolution=5, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "# Gather and sort saved frames\n",
    "frame_paths = sorted(save_dir.glob(\"batch_*.png\"))\n",
    "frames = [PILImage.open(p) for p in frame_paths]\n",
    "\n",
    "# Save GIF\n",
    "gif_path = \"training_evolution.gif\"\n",
    "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=50, loop=0)\n",
    "print(f\"GIF saved to {gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "\n",
    "def look_at(eye: torch.Tensor,\n",
    "            center: torch.Tensor,\n",
    "            up:    torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build a world→camera 4×4 view matrix given an eye position, a look-at center, and an up vector.\n",
    "    \"\"\"\n",
    "    z = (eye - center)\n",
    "    z = z / z.norm(dim=0, keepdim=True)\n",
    "    x = torch.cross(up, z)\n",
    "    x = x / x.norm(dim=0, keepdim=True)\n",
    "    y = torch.cross(z, x)\n",
    "    R = torch.stack([x, y, z], dim=0)      # 3×3 rotation\n",
    "    T = -R @ eye.view(3,1)                 # 3×1 translation\n",
    "    view = torch.eye(4, device=eye.device, dtype=eye.dtype)\n",
    "    view[:3,:3] = R\n",
    "    view[:3, 3] = T.squeeze()\n",
    "    return view\n",
    "\n",
    "def render_semihelical_gif(\n",
    "    means:          torch.Tensor,           # (N,3) sphere centers\n",
    "    radii:          torch.Tensor|float,\n",
    "    scene_center:   torch.Tensor,           # (3,)\n",
    "    scene_radius:   float,\n",
    "    K:              torch.Tensor,           # 3×3 intrinsics\n",
    "    width:          int,\n",
    "    height:         int,\n",
    "    fps:            int     = 15,           # playback frames per second\n",
    "    rotation_time:  float   = 5.0,          # seconds to go from +X→+Z\n",
    "    revolutions:    float   = 2.0,          # how many twists around Y-axis\n",
    "    up:             torch.Tensor = torch.tensor([0.,0,1]),\n",
    "    output_path:    str     = \"semihelical.gif\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Renders a helical camera path on the upper hemisphere of radius `scene_radius`,\n",
    "    starting at scene_center + (scene_radius,0,0) and ending at\n",
    "    scene_center + (0,0,scene_radius), twisting `revolutions` times around Y.\n",
    "    Produces a looping GIF at `fps` for a total duration of rotation_time.\n",
    "    \"\"\"\n",
    "    device = means.device\n",
    "    center = scene_center.to(device=device, dtype=means.dtype)\n",
    "    up_vec = up.to(device=device, dtype=means.dtype)\n",
    "\n",
    "    n_frames   = int(round(fps * rotation_time))\n",
    "    duration_ms = int(round(1000.0 / fps))\n",
    "\n",
    "    frames = []\n",
    "    for i in range(n_frames):\n",
    "        t   = i / (n_frames - 1)                # from 0 → 1\n",
    "        phi = t * (math.pi / 2)                # elevation from 0 → 90°\n",
    "        theta = t * (2 * math.pi * revolutions)  # azimuthal twist\n",
    "\n",
    "        # Parametric point on hemisphere surface (Z is up)\n",
    "        x = center[0] + scene_radius * math.cos(phi) * math.cos(theta)\n",
    "        y = center[1] + scene_radius * math.cos(phi) * math.sin(theta)\n",
    "        z = center[2] + scene_radius * math.sin(phi)\n",
    "        cam_pos = torch.tensor([x, y, z], device=device, dtype=means.dtype)\n",
    "\n",
    "        V = look_at(cam_pos, center, up_vec)  \n",
    "        alpha = rasterize_spheres(means, radii, V, K, width, height)  # (H,W,1)\n",
    "        a_np  = (alpha[...,0].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        rgb   = np.stack([a_np]*3, axis=-1)     # gray → RGB\n",
    "        frames.append(Image.fromarray(rgb))\n",
    "\n",
    "    # Save as a looping GIF\n",
    "    frames[0].save(\n",
    "        output_path,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=duration_ms,\n",
    "        loop=0\n",
    "    )\n",
    "    print(f\"Saved {output_path}: {n_frames} frames, {fps} FPS, {revolutions} revolutions.\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# --- example usage ---\n",
    "# Example data\n",
    "means = trainer.means\n",
    "N = means.shape[0]\n",
    "radii = thickness                             # uniform radius\n",
    "scene_center = torch.tensor(trainer.sampler.scene_center)\n",
    "scene_radius = 3.0\n",
    "\n",
    "W, H = 224, 224\n",
    "K = trainer.sampler.K\n",
    "\n",
    "render_semihelical_gif(\n",
    "    means, radii, scene_center, scene_radius,\n",
    "    K, W, H,\n",
    "    fps=120,\n",
    "    rotation_time=4.0,\n",
    "    revolutions=1.0,\n",
    "    output_path=\"semihelical.gif\"\n",
    ")\n",
    "print(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def plot_scene_with_camera_path(\n",
    "    means: torch.Tensor,\n",
    "    radii: torch.Tensor | float,\n",
    "    scene_center: torch.Tensor,\n",
    "    scene_radius: float,\n",
    "    revolutions: float = 3.0,\n",
    "    n_points: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots spheres at `means` with given `radii` and a helical camera path\n",
    "    on the upper hemisphere from (scene_radius,0,0) to (0,0,scene_radius).\n",
    "    \n",
    "    Parameters:\n",
    "    - means: (N,3) tensor of sphere centers.\n",
    "    - radii: either scalar or (N,) tensor of sphere radii.\n",
    "    - scene_center: (3,) tensor for the center of the hemisphere.\n",
    "    - scene_radius: radius of the hemisphere on which the camera moves.\n",
    "    - revolutions: number of full twists around the Y-axis.\n",
    "    - n_points: number of samples along the path.\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy\n",
    "    means_np = means.detach().cpu().numpy()\n",
    "    if torch.is_tensor(radii):\n",
    "        radii_np = radii.cpu().numpy()\n",
    "    else:\n",
    "        radii_np = np.full(means_np.shape[0], float(radii))\n",
    "    center = scene_center.cpu().numpy()\n",
    "\n",
    "    # Parameter t from 0 → 1\n",
    "    t = np.linspace(0, 1, n_points)\n",
    "    phi = t * (np.pi / 2)               # elevation angle from 0 to 90°\n",
    "    theta = t * (2 * np.pi * revolutions)  # azimuthal twist\n",
    "\n",
    "    # Camera positions on hemisphere\n",
    "    cam_x = center[0] + scene_radius * np.cos(phi) * np.cos(theta)\n",
    "    cam_y = center[1] + scene_radius * np.cos(phi) * np.sin(theta)\n",
    "    cam_z = center[2] + scene_radius * np.sin(phi)\n",
    "\n",
    "    # Set up 3D plot\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot each sphere\n",
    "    u = np.linspace(0, 2 * np.pi, 30)\n",
    "    v = np.linspace(0, np.pi, 30)\n",
    "    for center_pt, r in zip(means_np, radii_np):\n",
    "        x_s = center_pt[0] + r * np.outer(np.cos(u), np.sin(v))\n",
    "        y_s = center_pt[1] + r * np.outer(np.sin(u), np.sin(v))\n",
    "        z_s = center_pt[2] + r * np.outer(np.ones_like(u), np.cos(v))\n",
    "        ax.plot_surface(x_s, y_s, z_s, color='cyan', alpha=0.3, linewidth=0)\n",
    "\n",
    "    # Plot camera path\n",
    "    ax.plot(cam_x, cam_y, cam_z, 'r-', linewidth=2, label='Camera Path')\n",
    "    ax.scatter(cam_x[0], cam_y[0], cam_z[0], color='green', s=50, label='Start')\n",
    "    ax.scatter(cam_x[-1], cam_y[-1], cam_z[-1], color='black', s=50, label='End')\n",
    "    \n",
    "    # Plot scene center\n",
    "    ax.scatter(center[0], center[1], center[2], color='magenta', s=80, label='Scene Center')\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('3D Scene with Spheres and Camera Path')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "    # Example data\n",
    "means = trainer.means\n",
    "N = means.shape[0]\n",
    "radii = thickness                             # uniform radius\n",
    "scene_center = torch.tensor(trainer.sampler.scene_center)\n",
    "scene_radius = 3.0\n",
    "\n",
    "W, H = 224, 224\n",
    "K = trainer.sampler.K\n",
    "\n",
    "plot_scene_with_camera_path(\n",
    "    means, radii, scene_center, scene_radius,\n",
    "    revolutions=1.0, n_points=300\n",
    ")\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.sampler.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b42c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vimm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
