{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from source.cliploss import Loss\n",
    "from source.beziercurve import BezierCurve , CurveSet\n",
    "from source.diffrasterizer import rasterize_spheres\n",
    "from source.utils import load_scene\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from PIL import Image as PILImage\n",
    "save_dir = Path(\"training_frames\")\n",
    "save_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ad33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args = SimpleNamespace(\n",
    "    device=device,\n",
    "    percep_loss=\"none\",\n",
    "    train_with_clip=True,          # ✅ Enable CLIP loss\n",
    "    clip_weight=1.0,               # ✅ Set a non-zero weight\n",
    "    start_clip=0,\n",
    "    clip_conv_loss=1,              # ✅ Enable convolutional CLIP loss\n",
    "    clip_fc_loss_weight=0.1,\n",
    "    clip_text_guide=0.0,\n",
    "    num_aug_clip=4,\n",
    "    augemntations=[\"affine\"],\n",
    "    include_target_in_aug=False,\n",
    "    augment_both=False,\n",
    "    clip_model_name=\"ViT-B/32\",\n",
    "    clip_conv_loss_type=\"L2\",\n",
    "    clip_conv_layer_weights=[0.0, 0.5, 1.0, 1.0, 0]\n",
    ")\n",
    "\n",
    "criterion = Loss(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c56aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterizer = torch.compile(rasterize_spheres)\n",
    "device = 'cuda'\n",
    "W, H = 224, 224\n",
    "\n",
    "# Loss and optimizer setup\n",
    "\n",
    "# Load your scene (on CUDA)\n",
    "_, c2w_all, K = load_scene(\"../data/transforms_train.json\", W, H, device)\n",
    "c2w0 = c2w_all[0]\n",
    "w2c0 = torch.linalg.inv(c2w0)\n",
    "\n",
    "# Load target image\n",
    "to_tensor = T.ToTensor()\n",
    "target = Image.open(\"../data/snake.jpg\")\n",
    "target_t = to_tensor(target).to(device)      # (1,H,W)\n",
    "target_rgb = target_t.unsqueeze(0)\n",
    "target_rgb = torch.nn.functional.interpolate(target_rgb, size=(224, 224), mode='bilinear')\n",
    "# Your initial control‐point tensors\n",
    "init_pts1 = torch.tensor([\n",
    "    [-0.8,  0.6, 0.0],\n",
    "    [-0.5,  1.0, 0.3],\n",
    "    [ 0.2, -0.6, 0.2],\n",
    "    [ 0.8, -0.4, 0.0]\n",
    "], device=device)\n",
    "\n",
    "init_pts2 = torch.tensor([\n",
    "    [-0.7, -0.3, 0.0],\n",
    "    [-0.4,  0.7, 0.4],\n",
    "    [ 0.3, -0.5, 0.1],\n",
    "    [ 0.9,  0.2, 0.0]\n",
    "], device=device)\n",
    "\n",
    "init_pts3 = torch.tensor([\n",
    "    [ 0.7, -0.7, 0.0],\n",
    "    [ 0.3,  0.5, 0.3],\n",
    "    [-0.3, -0.6, 0.2],\n",
    "    [-0.8,  0.1, 0.0]\n",
    "], device=device)\n",
    "\n",
    "init_pts4 = torch.tensor([\n",
    "    [ 0.6,  0.8, 0.0],\n",
    "    [ 0.0,  1.2, 0.3],\n",
    "    [-0.5, -0.5, 0.2],\n",
    "    [-0.9, -0.2, 0.0]\n",
    "], device=device)\n",
    "\n",
    "# Create the CurveSet with exactly the curves you have\n",
    "curve_set = CurveSet([init_pts1, init_pts2, init_pts3, init_pts4], thickness=0.02, overlap=0.7, arc_samples=300, device=device)\n",
    "curve_set.to(device)\n",
    "\n",
    "# Optimizer over all curve parameters\n",
    "opt = optim.Adam(curve_set.parameters(), lr=1e-2)\n",
    "\n",
    "# Prepare plotting\n",
    "plt.ion()\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Training loop\n",
    "for it in range(1001):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Render all curves\n",
    "    means, thicknesses = curve_set()  # (N,3), (N,)\n",
    "    img = rasterizer(means, thicknesses, w2c0, K, W, H)  # (H,W,1)\n",
    "    img = img.permute(2, 0, 1)  # (1,H,W)\n",
    "    img = img.repeat(3, 1, 1).unsqueeze(0)  # (3,H,W)\n",
    "\n",
    "\n",
    "    # Compute loss and backprop\n",
    "    loss = criterion(img, target_rgb,it)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # Plot every 5 iterations\n",
    "    if it % 5 == 0:\n",
    "        curr = img[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        plt.clf()\n",
    "        plt.imshow(curr, vmin=0, vmax=1)\n",
    "        plt.title(f\"Iter {it:3d} — Loss: {loss.item():.4f}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the frame\n",
    "        frame_path = save_dir / f\"iter_{it:04d}.png\"\n",
    "        plt.savefig(frame_path)\n",
    "        plt.pause(0.01)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "# Gather and sort saved frames\n",
    "frame_paths = sorted(save_dir.glob(\"iter_*.png\"))\n",
    "frames = [PILImage.open(p) for p in frame_paths]\n",
    "\n",
    "# Save GIF\n",
    "gif_path = \"training_evolution.gif\"\n",
    "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=50, loop=0)\n",
    "print(f\"GIF saved to {gif_path}\")\n",
    "\n",
    "for p in frame_paths:\n",
    "    p.unlink()\n",
    "save_dir.rmdir()\n",
    "print(\"Temporary files cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c54fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Show generated image (convert to H×W×C)\n",
    "plt.subplot(1, 2, 1)\n",
    "img_np = img[0].permute(1, 2, 0).cpu().detach().numpy()  # (3, H, W) → (H, W, 3)\n",
    "plt.imshow(img_np, vmin=0, vmax=1)\n",
    "plt.title(\"Generated Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Show target image (convert to H×W×C)\n",
    "plt.subplot(1, 2, 2)\n",
    "target_np = target_rgb[0].permute(1, 2, 0).cpu().numpy()  # (3, H, W) → (H, W, 3)\n",
    "plt.imshow(target_np, vmin=0, vmax=1)\n",
    "plt.title(\"Target Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_spheres(means: np.ndarray, radii: np.ndarray, resolution: int = 20):\n",
    "    \"\"\"\n",
    "    Plot 3D spheres centered at `means` with given `radii`.\n",
    "\n",
    "    Args:\n",
    "        means      (N,3) numpy array of sphere centers\n",
    "        radii      (N,) numpy array of sphere radii\n",
    "        resolution number of subdivisions in θ,ϕ (higher → smoother)\n",
    "    \"\"\"\n",
    "    # parameterize a unit sphere\n",
    "    u = np.linspace(0, 2*np.pi, resolution)\n",
    "    v = np.linspace(0, np.pi,   resolution)\n",
    "    uu, vv = np.meshgrid(u, v)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for (x0, y0, z0), r in zip(means, radii):\n",
    "        # sphere surface at center (x0,y0,z0)\n",
    "        x = x0 + r * np.cos(uu) * np.sin(vv)\n",
    "        y = y0 + r * np.sin(uu) * np.sin(vv)\n",
    "        z = z0 + r * np.cos(vv)\n",
    "\n",
    "        fig.add_trace(go.Surface(\n",
    "            x=x, y=y, z=z,\n",
    "            showscale=False,\n",
    "            opacity=0.6,\n",
    "            lighting=dict(ambient=0.5, diffuse=0.5, roughness=0.9),\n",
    "            hoverinfo='skip'\n",
    "        ))\n",
    "\n",
    "    # make axes equal and add some padding\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='X', backgroundcolor=\"rgb(230, 230,230)\"),\n",
    "            yaxis=dict(title='Y', backgroundcolor=\"rgb(230, 230,230)\"),\n",
    "            zaxis=dict(title='Z', backgroundcolor=\"rgb(230, 230,230)\"),\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        width=800, height=800,\n",
    "        title=\"3D Spheres at Bézier Sample Locations\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "\n",
    "# assuming you have your torch tensors `means` and `thicknesses` already:\n",
    "import torch\n",
    "\n",
    "# means: (N,3) tensor on CPU or GPU\n",
    "# thicknesses: (N,) world‐space radii\n",
    "means_np = means.detach().cpu().numpy()\n",
    "radii_np = thicknesses.detach().cpu().numpy()\n",
    "\n",
    "plot_spheres(means_np, radii_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5525b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vimm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
